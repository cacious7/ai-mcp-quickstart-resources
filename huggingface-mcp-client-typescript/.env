# Configuration for Hugging Face MCP Client

# Hugging Face settings
HUGGINGFACE_API_KEY=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
HUGGINGFACE_API_URL=https://api-inference.huggingface.co/models

# Model Selection - Choose one of:
# - mistralai/Mistral-7B-Instruct-v0.2 - Good for instruction following
# - meta-llama/Llama-2-7b-chat-hf - Balanced performance
# - OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5 - Good for function calling

# Current model to use
HUGGINGFACE_MODEL=meta-llama/Llama-2-7b-chat-hf

# Model parameters (adjust for specific models as needed)
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=1000
